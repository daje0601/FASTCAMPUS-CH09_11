{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087baa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29eb6284-ea43-4b6b-ab7d-cbd9844890f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/text_to_sql/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# 제로샷 테스트를 하기 위해 모델을 다운받고, 인퍼런스를 실행합니다. \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-Coder-7B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": 'Task:라틴 아메리카/카리브해 지역의 인구가 783(7.5%)가 될 때, 아시아의 인구는 얼마가 될까요?\\nSQL Table:CREATE TABLE table_22767 (\\n    \"Year\" real,\\n    \"World\" real,\\n    \"Asia\" text,\\n    \"Africa\" text,\\n    \"Europe\" text,\\n    \"Latin America/Caribbean\" text,\\n    \"Northern America\" text,\\n    \"Oceania\" text\\n)\\nQuery:'}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "# model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# generated_ids = model.generate(\n",
    "#     **model_inputs,\n",
    "#     max_new_tokens=512\n",
    "# )\n",
    "# generated_ids = [\n",
    "#     output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "# ]\n",
    "\n",
    "# response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb60a96-a44a-4a0d-92b9-5b3103e4806e",
   "metadata": {},
   "source": [
    "# 제로샷 테스트 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaaf501-2e89-4909-a210-8f454b06028c",
   "metadata": {},
   "source": [
    "### 정답 \n",
    "SELECT \"Asia\" FROM table_22767 WHERE \"Latin America/Caribbean\" = \\'783 (7.5%)\\'\n",
    "\n",
    "### 생성 결과\n",
    "SELECT (783 / 0.075) AS World_Population, (0.15 * (783 / 0.075)) AS Asia_Population;\n",
    "\n",
    "잘못된 결과를 생성하고 있고 우리가 원하지 않는 문장들이 포함되어 있습니다.   \n",
    "Fine-Tuning을 통해 이러한 문제를 해결해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc644522-d263-4768-a139-a4d8fd3cd0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import trl\n",
    "import torch\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "from peft import LoraConfig, AutoPeftModelForCausalLM\n",
    "\n",
    "import wandb\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForCausalLM,\n",
    "                          BitsAndBytesConfig,\n",
    "                          TrainingArguments,\n",
    "                          pipeline)\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5079e699-d44d-44a5-b839-fb5e542737a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version       : 2.5.1\n",
      "Transformers version  : 4.47.1\n",
      "TRL version           : 0.13.0\n",
      "CUDA available        : True\n",
      "CUDA version      : 12.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version       : {torch.__version__}\")\n",
    "print(f\"Transformers version  : {transformers.__version__}\")\n",
    "print(f\"TRL version           : {trl.__version__}\")\n",
    "print(f\"CUDA available        : {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version      : {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcf35f-c1cc-4c37-b946-28759da62a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "login(\n",
    "  token=\"Huggingface_Token\", # 여기에 토큰 추가 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2dae205-17f5-4e2f-9888-55e61dfe8ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'response', 'source', 'text', 'ko_instruction'],\n",
       "        num_rows: 262208\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = datasets.load_dataset(\"Clinton/text-to-sql-v1\")\n",
    "dataset = datasets.load_dataset(\"daje/kotext-to-sql-v1\")\n",
    "dataset     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c13429c8-5d5d-421c-9930-15f496d90c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910 13\n"
     ]
    }
   ],
   "source": [
    "def add_length_column(dataset):\n",
    "    df = dataset.to_pandas()\n",
    "    df[\"total_length\"] = 0\n",
    "    for column_name in [\"ko_instruction\", \"input\", \"response\"]:\n",
    "        num_words = df[column_name].astype(str).str.split().apply(len)\n",
    "        df[\"total_length\"] += num_words\n",
    "\n",
    "    return df\n",
    "\n",
    "df = add_length_column(dataset[\"train\"])\n",
    "\n",
    "def filter_by_total_length(df, difficulty, number_of_samples, random_state=8888):  # random_state 추가\n",
    "    if difficulty == \"easy\":\n",
    "        return df[df[\"total_length\"].between(10, 100)].sample(n=number_of_samples, random_state=random_state)  # iloc 대신 sample 사용\n",
    "    elif difficulty == \"moderate\":\n",
    "        return df[df[\"total_length\"].between(101, 300)].sample(n=number_of_samples, random_state=random_state)\n",
    "    elif difficulty == \"difficult\":\n",
    "        return df[df[\"total_length\"].between(301, 1000)].sample(n=number_of_samples, random_state=random_state)\n",
    "\n",
    "print(max(df[\"total_length\"].to_list()), min(df[\"total_length\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a456737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 300/300 [00:00<00:00, 7997.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful programmer assistant that excels at SQL. Below are sql tables schemas paired with instruction that describes a task. Using valid SQLite, write a response that appropriately completes the request for the provided tables.<|im_end|>\n",
      "<|im_start|>user\n",
      "### instruction:매일 오후 5시에 나가도 되나요, 370번과 489번을 타면? ### Input:CREATE TABLE course_prerequisite (\n",
      "    pre_course_id int,\n",
      "    course_id int\n",
      ")\n",
      "\n",
      "CREATE TABLE area (\n",
      "    course_id int,\n",
      "    area varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE offering_instructor (\n",
      "    offering_instructor_id int,\n",
      "    offering_id int,\n",
      "    instructor_id int\n",
      ")\n",
      "\n",
      "CREATE TABLE student (\n",
      "    student_id int,\n",
      "    lastname varchar,\n",
      "    firstname varchar,\n",
      "    program_id int,\n",
      "    declare_major varchar,\n",
      "    total_credit int,\n",
      "    total_gpa float,\n",
      "    entered_as varchar,\n",
      "    admit_term int,\n",
      "    predicted_graduation_semester int,\n",
      "    degree varchar,\n",
      "    minor varchar,\n",
      "    internship varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE program (\n",
      "    program_id int,\n",
      "    name varchar,\n",
      "    college varchar,\n",
      "    introduction varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE student_record (\n",
      "    student_id int,\n",
      "    course_id int,\n",
      "    semester int,\n",
      "    grade varchar,\n",
      "    how varchar,\n",
      "    transfer_source varchar,\n",
      "    earn_credit varchar,\n",
      "    repeat_term varchar,\n",
      "    test_id varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE course_offering (\n",
      "    offering_id int,\n",
      "    course_id int,\n",
      "    semester int,\n",
      "    section_number int,\n",
      "    start_time time,\n",
      "    end_time time,\n",
      "    monday varchar,\n",
      "    tuesday varchar,\n",
      "    wednesday varchar,\n",
      "    thursday varchar,\n",
      "    friday varchar,\n",
      "    saturday varchar,\n",
      "    sunday varchar,\n",
      "    has_final_project varchar,\n",
      "    has_final_exam varchar,\n",
      "    textbook varchar,\n",
      "    class_address varchar,\n",
      "    allow_audit varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE semester (\n",
      "    semester_id int,\n",
      "    semester varchar,\n",
      "    year int\n",
      ")\n",
      "\n",
      "CREATE TABLE requirement (\n",
      "    requirement_id int,\n",
      "    requirement varchar,\n",
      "    college varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE program_course (\n",
      "    program_id int,\n",
      "    course_id int,\n",
      "    workload int,\n",
      "    category varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE gsi (\n",
      "    course_offering_id int,\n",
      "    student_id int\n",
      ")\n",
      "\n",
      "CREATE TABLE program_requirement (\n",
      "    program_id int,\n",
      "    category varchar,\n",
      "    min_credit int,\n",
      "    additional_req varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE instructor (\n",
      "    instructor_id int,\n",
      "    name varchar,\n",
      "    uniqname varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE comment_instructor (\n",
      "    instructor_id int,\n",
      "    student_id int,\n",
      "    score int,\n",
      "    comment_text varchar\n",
      ")\n",
      "\n",
      "CREATE TABLE course (\n",
      "    course_id int,\n",
      "    name varchar,\n",
      "    department varchar,\n",
      "    number varchar,\n",
      "    credits varchar,\n",
      "    advisory_requirement varchar,\n",
      "    enforced_requirement varchar,\n",
      "    description varchar,\n",
      "    num_semesters int,\n",
      "    num_enrolled int,\n",
      "    has_discussion varchar,\n",
      "    has_lab varchar,\n",
      "    has_projects varchar,\n",
      "    has_exams varchar,\n",
      "    num_reviews int,\n",
      "    clarity_score int,\n",
      "    easiness_score int,\n",
      "    helpfulness_score int\n",
      ")\n",
      "\n",
      "CREATE TABLE course_tags_count (\n",
      "    course_id int,\n",
      "    clear_grading int,\n",
      "    pop_quiz int,\n",
      "    group_projects int,\n",
      "    inspirational int,\n",
      "    long_lectures int,\n",
      "    extra_credit int,\n",
      "    few_tests int,\n",
      "    good_feedback int,\n",
      "    tough_tests int,\n",
      "    heavy_papers int,\n",
      "    cares_for_students int,\n",
      "    heavy_assignments int,\n",
      "    respected int,\n",
      "    participation int,\n",
      "    heavy_reading int,\n",
      "    tough_grader int,\n",
      "    hilarious int,\n",
      "    would_take_again int,\n",
      "    good_lecture int,\n",
      "    no_skip int\n",
      ")\n",
      "\n",
      "CREATE TABLE jobs (\n",
      "    job_id int,\n",
      "    job_title varchar,\n",
      "    description varchar,\n",
      "    requirement varchar,\n",
      "    city varchar,\n",
      "    state varchar,\n",
      "    country varchar,\n",
      "    zip int\n",
      ")\n",
      "\n",
      "CREATE TABLE ta (\n",
      "    campus_job_id int,\n",
      "    student_id int,\n",
      "    location varchar\n",
      ") ### response:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "SELECT COUNT(*) = 0 FROM course INNER JOIN course_offering ON course.course_id = course_offering.course_id INNER JOIN semester ON semester.semester_id = course_offering.semester WHERE (course.number = 370 OR course.number = 489) AND course_offering.end_time > '17:00:00' AND semester.semester = 'WN' AND semester.year = 2016<|im_end|><|im_end|>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# trl docs에 보면 이와 같은 방식으로 SFT Trainer용 데이터를 만들 수 있습니다.\n",
    "# docs에서는 eos_token을 별도로 추가하라는 안내는 없지만, 저자는 습관적으로 eos_token을 붙혀줍니다.\n",
    "def get_chat_format(element):\n",
    "    system_prompt = (\n",
    "        \"You are a helpful programmer assistant that excels at SQL. \"\n",
    "        \"Below are sql tables schemas paired with instruction that describes a task. \"\n",
    "        \"Using valid SQLite, write a response that appropriately completes the request for the provided tables.\"\n",
    "    )\n",
    "    user_prompt = \"### instruction:{ko_instruction} ### Input:{input} ### response:\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt.format_map(element)},\n",
    "            {\"role\": \"assistant\", \"content\": element[\"response\"]+tokenizer.eos_token},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "tokenizer.padding_side = 'right'                      \n",
    "\n",
    "def tokenize(element):\n",
    "    # 참고 코드에서처럼, apply_chat_template 사용\n",
    "    formatted = tokenizer.apply_chat_template(\n",
    "        get_chat_format(element)[\"messages\"],  # get_chat_format 반환 형식을 맞춰줍니다.\n",
    "        tokenize=False\n",
    "    )\n",
    "    outputs = tokenizer(formatted)\n",
    "    return {\n",
    "        \"input_ids\": outputs[\"input_ids\"],\n",
    "        \"attention_mask\": outputs[\"attention_mask\"],\n",
    "    }\n",
    "    \n",
    "# 데이터를 일괄적으로 대화형식으로 변경합니다.\n",
    "\n",
    "easy = filter_by_total_length(df, \"easy\", 100)\n",
    "medium = filter_by_total_length(df, \"moderate\", 100)\n",
    "hard = filter_by_total_length(df, \"difficult\", 100)\n",
    "dataset = pd.concat([easy, medium, hard])\n",
    "dataset = dataset.sample(frac=1, random_state=8888)  # random_state 추가\n",
    "dataset = Dataset.from_pandas(dataset)\n",
    "easy.shape, medium.shape, hard.shape, dataset.shape\n",
    "\n",
    "temp_dataset = dataset.map(get_chat_format, remove_columns=dataset.features, batched=False)\n",
    "\n",
    "# train과 test 데이터를 0.9와 0.1로 분할합니다.\n",
    "temp_dataset = temp_dataset.train_test_split(test_size=0.05, seed=42)\n",
    "\n",
    "temp = tokenizer.apply_chat_template(temp_dataset[\"train\"][0][\"messages\"], tokenizer=False)\n",
    "print(tokenizer.decode(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1563b736-67bb-416c-8cd4-07541262cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일부 데이터만 샘플링하고 싶은 경우 \n",
    "# easy = filter_by_total_length(df, \"easy\", 10000)\n",
    "# medium = filter_by_total_length(df, \"moderate\", 10000)\n",
    "# hard = filter_by_total_length(df, \"difficult\", 2000)\n",
    "# dataset = pd.concat([easy, medium, hard])\n",
    "# dataset = dataset.sample(frac=1, random_state=8888)  # random_state 추가\n",
    "# dataset = Dataset.from_pandas(dataset)\n",
    "# easy.shape, medium.shape, hard.shape, dataset.shape\n",
    "\n",
    "# 전체 데이터로 학습을 할 경우 \n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b305b4e-fed0-4772-98af-19c98e403142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 262208/262208 [00:14<00:00, 18722.44 examples/s]\n",
      "Map: 100%|██████████| 256963/256963 [03:08<00:00, 1365.62 examples/s]\n",
      "Map: 100%|██████████| 5245/5245 [00:03<00:00, 1346.73 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# trl docs에 보면 이와 같은 방식으로 SFT Trainer용 데이터를 만들 수 있습니다.\n",
    "# docs에서는 eos_token을 별도로 추가하라는 안내는 없지만, 저자는 습관적으로 eos_token을 붙혀줍니다.\n",
    "def get_chat_format(element):\n",
    "    system_prompt = (\n",
    "        \"You are a helpful programmer assistant that excels at SQL. \"\n",
    "        \"Below are sql tables schemas paired with instruction that describes a task. \"\n",
    "        \"Using valid SQLite, write a response that appropriately completes the request for the provided tables.\"\n",
    "    )\n",
    "    user_prompt = \"### instruction:{ko_instruction} ### Input:{input} ### response:\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt.format_map(element)},\n",
    "            {\"role\": \"assistant\", \"content\": element[\"response\"]+tokenizer.eos_token},  # 여기 닫는 괄호 추가\n",
    "        ]\n",
    "    }\n",
    "\n",
    "tokenizer.padding_side = 'right'                      \n",
    "\n",
    "def apply_chat_format(element):\n",
    "    \"\"\"\n",
    "    1) get_chat_format(element)를 호출해서\n",
    "       messages를 생성한 뒤, Dataset에 저장할 dict로 반환합니다.\n",
    "    \"\"\"\n",
    "    chat_format = get_chat_format(element)  # get_chat_format은 원본 코드 그대로 사용\n",
    "    return {\n",
    "        \"messages\": chat_format[\"messages\"]\n",
    "    }\n",
    "\n",
    "def tokenize_messages(element):\n",
    "    \"\"\"\n",
    "    2) apply_chat_template + tokenizer(...)를 통해\n",
    "       input_ids와 attention_mask를 만들어 반환합니다.\n",
    "    \"\"\"\n",
    "    # 위 단계에서 \"messages\"가 이미 Dataset에 들어가있다고 가정\n",
    "    formatted = tokenizer.apply_chat_template(\n",
    "        element[\"messages\"],  # messages 리스트\n",
    "        tokenize=False\n",
    "    )\n",
    "    outputs = tokenizer(formatted)\n",
    "    return {\n",
    "        \"input_ids\": outputs[\"input_ids\"],\n",
    "        \"attention_mask\": outputs[\"attention_mask\"]\n",
    "    }\n",
    "\n",
    "# train과 test 데이터를 0.9와 0.1로 분할합니다.\n",
    "dataset = dataset.map(\n",
    "    apply_chat_format,\n",
    "    batched=False,\n",
    "    remove_columns=dataset.features,  # 원하시면 제거\n",
    ")\n",
    "dataset = dataset.train_test_split(test_size=0.02)\n",
    "# dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
    "# dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    tokenize_messages,\n",
    "    batched=False,\n",
    "    remove_columns=[\"messages\"],  # 이제 messages를 더이상 쓰지 않는다면 제거\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db814ead-f19d-4b76-8a28-a368c7a9d6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 256963\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 5245\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1bad9-54b6-4cc1-ade5-43708589a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "response_template = \"<|im_start|>assistant\\n\"\n",
    "# 만약 실제로 줄바꿈까지 포함되어 있다면 \\n까지 넣어줘야 합니다.\n",
    "# response_template = \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "\n",
    "response_template_ids = tokenizer.encode(response_template, add_special_tokens=False)\n",
    "collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template_ids,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d937987e-27c6-46a9-8561-31e164ab132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "        lora_alpha=128,                            \n",
    "        lora_dropout=0.05,                         # Lora 학습 때 사용할 dropout 확률을 지정합니다. 드롭아웃 확률은 과적합 방지를 위해 학습 중 무작위로 일부 뉴런을 비활성화하는 비율을 지정합니다.\n",
    "        r=256,                                     # Lora의 저차원 공간의 랭크를 지정합니다. 랭크가 높을수록 모델의 표현력이 증가하지만, 계산 비용도 증가합니다.\n",
    "        bias=\"none\",                               # Lora 적용 시 바이어스를 사용할지 여부를 설정합니다. \"none\"으로 설정하면 바이어스를 사용하지 않습니다.\n",
    "        target_modules=[\"q_proj\", \"o_proj\",        # Lora를 적용할 모델의 모듈 리스트입니다.\n",
    "                        \"k_proj\", \"v_proj\"\n",
    "                        \"up_proj\", \"down_proj\",\n",
    "                        \"gate_proj\",\n",
    "                        ],\n",
    "        task_type=\"CAUSAL_LM\",                     # 미세 조정 작업 유형을 CAUSAL_LM으로 지정하여 언어 모델링 작업을 수행합니다.\n",
    ")\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"Qwen2.5-260000_ko\", # 모델 저장 및 허브 업로드를 위한 디렉토리 지정 합니다.\n",
    "    num_train_epochs=1,                   # number of training epochs\n",
    "    # max_steps=100,                          # 100스텝 동안 훈련 수행합니다.\n",
    "    per_device_train_batch_size=1,          # 배치 사이즈 설정 합니다.\n",
    "    gradient_accumulation_steps=2,          # 4스텝마다 역전파 및 가중치 업데이트합니다.\n",
    "    gradient_checkpointing=False,            # 메모리 절약을 위해 그래디언트 체크포인팅 사용합니다.\n",
    "    optim=\"adamw_torch_fused\",              # 메모리 효율화할 수 있는 fused AdamW 옵티마이저 사용합니다.\n",
    "    logging_steps=5000,                       # 10스텝마다 로그 기록합니다.\n",
    "    save_strategy=\"steps\",                  # 매 에폭마다 체크포인트 저장합니다.\n",
    "    learning_rate=5e-5,                     # 학습률 2e-4로 설정 (QLoRA 논문 기반)합니다.\n",
    "    bf16=True,                              # 정밀도 설정으로 학습 속도 향상합니다.\n",
    "    tf32=True,\n",
    "    max_grad_norm=0.3,                      # 그래디언트 클리핑 값 0.3으로 설정합니다.\n",
    "    warmup_ratio=0.03,                      # 워밍업 비율 0.03으로 설정 (QLoRA 논문 기반)합니다.\n",
    "    lr_scheduler_type=\"constant\",           # 일정한 학습률 스케줄러 사용합니다.\n",
    "    push_to_hub=False,                       # 훈련된 모델을 Hugging Face Hub에 업로드합니다.\n",
    "    report_to=\"wandb\",                      # wandb로 매트릭 관찰합니다.\n",
    ")\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219029f0-b5fc-4c91-ac39-e4cbec97c955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdaje0601\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/workspace/text_to_sql/wandb/run-20250109_153218-qi4lrj6v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/daje0601/huggingface/runs/qi4lrj6v' target=\"_blank\">Qwen2.5-260000_ko</a></strong> to <a href='https://wandb.ai/daje0601/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/daje0601/huggingface' target=\"_blank\">https://wandb.ai/daje0601/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/daje0601/huggingface/runs/qi4lrj6v' target=\"_blank\">https://wandb.ai/daje0601/huggingface/runs/qi4lrj6v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='389' max='128481' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   389/128481 01:57 < 10:49:27, 3.29 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trainer를 학습합니다.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae404e1e-e459-450d-b2ea-42ae54e6516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 초기화\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3b01b8d-ba39-47ec-a8bc-b56e19911f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "707bb01f-83a1-44b2-835b-4ada72d42fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 5245\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "eval_dataset = load_dataset(\"json\", data_files=\"/root/workspace/text_to_sql/test_dataset.json\", split=\"train\")\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c99aa7e0-4e73-4b48-9e97-d47a69a88072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'You are a helpful programmer assistant that excels at SQL. Below are sql tables schemas paired with instruction that describes a task. Using valid SQLite, write a response that appropriately completes the request for the provided tables.',\n",
       "  'role': 'system'},\n",
       " {'content': '### instruction:calculate the maximum days for which patients who died before 2155 stayed in hospital. ### Input:CREATE TABLE diagnoses (\\n    subject_id text,\\n    hadm_id text,\\n    icd9_code text,\\n    short_title text,\\n    long_title text\\n)\\n\\nCREATE TABLE lab (\\n    subject_id text,\\n    hadm_id text,\\n    itemid text,\\n    charttime text,\\n    flag text,\\n    value_unit text,\\n    label text,\\n    fluid text\\n)\\n\\nCREATE TABLE demographic (\\n    subject_id text,\\n    hadm_id text,\\n    name text,\\n    marital_status text,\\n    age text,\\n    dob text,\\n    gender text,\\n    language text,\\n    religion text,\\n    admission_type text,\\n    days_stay text,\\n    insurance text,\\n    ethnicity text,\\n    expire_flag text,\\n    admission_location text,\\n    discharge_location text,\\n    diagnosis text,\\n    dod text,\\n    dob_year text,\\n    dod_year text,\\n    admittime text,\\n    dischtime text,\\n    admityear text\\n)\\n\\nCREATE TABLE prescriptions (\\n    subject_id text,\\n    hadm_id text,\\n    icustay_id text,\\n    drug_type text,\\n    drug text,\\n    formulary_drug_cd text,\\n    route text,\\n    drug_dose text\\n)\\n\\nCREATE TABLE procedures (\\n    subject_id text,\\n    hadm_id text,\\n    icd9_code text,\\n    short_title text,\\n    long_title text\\n) ### response:',\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0][\"messages\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aac672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc02e0e-8ed3-4a19-a896-642b83115032",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "sql_chat_completion = client.chat.completions.create(\n",
    "    model=\"lora_adapter1\",\n",
    "    messages=eval_dataset[idx][\"messages\"][:2],\n",
    "    temperature=0.1,\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "\n",
    "# merged를 한경우 \n",
    "# idx = 0\n",
    "# sql_chat_completion = client.chat.completions.create(\n",
    "#     model=\"daje/Qwen2.5-coder-7B-en-all-merged\",\n",
    "#     messages=eval_dataset[idx][\"messages\"][:2],\n",
    "#     temperature=0.1,\n",
    "#     max_tokens=500,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48ba06bf-6b45-4760-a851-85186ba56dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'SELECT MAX(demographic.days_stay) FROM demographic WHERE demographic.dod_year < \"2155.0\"<|im_end|>',\n",
       " 'role': 'assistant'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[idx][\"messages\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a821e81-e17a-46c0-9e92-827bf46368fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT MAX(demographic.days_stay) FROM demographic WHERE demographic.dod_year < \"2155.0\"\n"
     ]
    }
   ],
   "source": [
    "print(sql_chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19a16ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이런 경우 때문에 OpenAI 채점이 필요합니다. \n",
    "eval_dataset[idx][\"messages\"][2][\"content\"].replace(\"<|im_end|>\", \"\").strip() == sql_chat_completion.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e867db3-c312-445d-b43f-cfed21b4e0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5245/5245 [46:23<00:00,  1.88it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm \n",
    "result = [] \n",
    "for idx in tqdm(range(len(eval_dataset))):\n",
    "    sql_chat_completion = client.chat.completions.create(\n",
    "    model=\"lora_adapter1\",\n",
    "    messages=eval_dataset[idx][\"messages\"][:2],\n",
    "    temperature=0.1,\n",
    "    max_tokens=500,\n",
    "    )\n",
    "    result.append(\n",
    "        (\n",
    "            eval_dataset[idx][\"messages\"][:2],\n",
    "            eval_dataset[idx][\"messages\"][2][\"content\"], \n",
    "            sql_chat_completion.choices[0].message.content\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc4e8126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과가 /root/workspace/text_to_sql/inference_output_qwen2.5_en_20250112_120251.json 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "from datetime import datetime\n",
    "\n",
    "# 실수로 다시 실행해도 파일이 사라지지 않도록 하기 위해 timestamp를 사용하는걸 습관화하시는게 좋습니다. \n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = f\"/root/workspace/text_to_sql/inference_output_qwen2.5_en_{timestamp}.json\"\n",
    " # 저장할 파일 이름\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"결과가 {output_file} 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144deccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'content': 'You are a helpful programmer assistant that excels at SQL. Below are sql tables schemas paired with instruction that describes a task. Using valid SQLite, write a response that appropriately completes the request for the provided tables.',\n",
       "   'role': 'system'},\n",
       "  {'content': '### instruction:calculate the maximum days for which patients who died before 2155 stayed in hospital. ### Input:CREATE TABLE diagnoses (\\n    subject_id text,\\n    hadm_id text,\\n    icd9_code text,\\n    short_title text,\\n    long_title text\\n)\\n\\nCREATE TABLE lab (\\n    subject_id text,\\n    hadm_id text,\\n    itemid text,\\n    charttime text,\\n    flag text,\\n    value_unit text,\\n    label text,\\n    fluid text\\n)\\n\\nCREATE TABLE demographic (\\n    subject_id text,\\n    hadm_id text,\\n    name text,\\n    marital_status text,\\n    age text,\\n    dob text,\\n    gender text,\\n    language text,\\n    religion text,\\n    admission_type text,\\n    days_stay text,\\n    insurance text,\\n    ethnicity text,\\n    expire_flag text,\\n    admission_location text,\\n    discharge_location text,\\n    diagnosis text,\\n    dod text,\\n    dob_year text,\\n    dod_year text,\\n    admittime text,\\n    dischtime text,\\n    admityear text\\n)\\n\\nCREATE TABLE prescriptions (\\n    subject_id text,\\n    hadm_id text,\\n    icustay_id text,\\n    drug_type text,\\n    drug text,\\n    formulary_drug_cd text,\\n    route text,\\n    drug_dose text\\n)\\n\\nCREATE TABLE procedures (\\n    subject_id text,\\n    hadm_id text,\\n    icd9_code text,\\n    short_title text,\\n    long_title text\\n) ### response:',\n",
       "   'role': 'user'}],\n",
       " 'SELECT MAX(demographic.days_stay) FROM demographic WHERE demographic.dod_year < \"2155.0\"<|im_end|>',\n",
       " 'SELECT MAX(demographic.days_stay) FROM demographic WHERE demographic.dod_year < \"2155.0\"']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "output_file = \"/root/workspace/text_to_sql/inference_output_qwen2.5_en_20250112_120251.json\"\n",
    "\n",
    "with open(output_file, \"r\") as file:\n",
    "    result = json.load(file)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d66126-1e7f-4e6d-bc99-d329d93b1886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.47%\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 1. 1차 필터: Exact Match\n",
    "#    (문자열이 완전히 동일하면 True, 아니면 False)\n",
    "# ------------------------------------------------------------------------------\n",
    "generated_result = [temp[1].replace(\"<|im_end|>\", \"\").strip() == temp[2].replace(\"<|im_end|>\", \"\").strip() for temp in result]\n",
    "\n",
    "# Exact Match 기준으로 ACC(정확도)를 구합니다.\n",
    "accuracy = sum(generated_result)/len(generated_result)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c01d2163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2차 OpenAI 검증] Exact Match로는 1234개가 불일치로 간주되어, OpenAI로 의미 비교를 진행합니다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/text_to_sql/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "from pqdm.processes import pqdm\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. False(= 서로 다른 쿼리)인 것만 모아서 OpenAI에 의미적 비교\n",
    "# ------------------------------------------------------------------------------\n",
    "differing_items = []  # (index, problem, generated_sql, ground_truth_sql)\n",
    "for i, is_match in enumerate(generated_result):\n",
    "    if not is_match:\n",
    "        problem_desc, gen_sql, gt_sql = result[i]\n",
    "        differing_items.append((i, problem_desc, gen_sql, gt_sql))\n",
    "\n",
    "print(f\"[2차 OpenAI 검증] Exact Match로는 {len(differing_items)}개가 불일치로 간주되어, OpenAI로 의미 비교를 진행합니다.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231db791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# OpenAI 및 Pydantic 설정\n",
    "# ------------------------------------------------------------------------------\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# 결과 파일 저장 폴더\n",
    "save_folder = Path(\"/root/workspace/text_to_sql/openai_result_qwen2.5_all-en\")\n",
    "save_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class SqlComparisonResult(BaseModel):\n",
    "    # answer: 1 (의미적으로 동일) 또는 0 (의미적으로 다름)\n",
    "    answer: int\n",
    "    explanation: str\n",
    "\n",
    "\n",
    "def one_compare_sql_semantics(item_tuple) -> dict:\n",
    "    \"\"\"\n",
    "    item_tuple: (idx, problem_desc, gen_sql, gt_sql)\n",
    "    OpenAI에 의미적 비교 요청 -> 'answer'(1/0), 'explanation' 반환\n",
    "    \"\"\"\n",
    "    idx, problem_description, generated_query, ground_truth_query = item_tuple\n",
    "    save_path = save_folder / f\"result_{idx}.json\"\n",
    "\n",
    "    # 이미 결과 파일이 존재하면, 재요청하지 않고 스킵\n",
    "    if save_path.exists():\n",
    "        print(f\"[{idx}] 이미 파일이 있습니다.\")\n",
    "        # 저장된 결과 불러오기\n",
    "        return None\n",
    "\n",
    "    # 프롬프트 작성\n",
    "    prompt = \"\"\"아래에는 한 개의 문제와 두 개의 SQL 쿼리가 주어집니다.\n",
    "\n",
    "이때, \"두 쿼리가 문자열로 달라도 실제로 동일한 결과를 반환하는지\"를 판단하세요.  \n",
    "구체적으로 다음 기준에 따라 판정하십시오:\n",
    "\n",
    "1. 결과 집합(ROW 세트)이 동일한지 여부만을 판단하십시오.\n",
    "- 대소문자 차이, 공백, 세미콜론 유무, 쿼리 포맷(줄바꿈 등), 작은따옴표 vs 큰따옴표, \n",
    "    테이블/컬럼 별칭 등이 다르더라도 결과 집합이 같다면 '동일'이라고 간주합니다.\n",
    "2. 문법상 다른 함수나 구조를 사용했더라도 결과가 같으면 동일합니다.\n",
    "- 예: GROUP BY 대상이 달라도 실제 결과가 동일하면 '동일'\n",
    "        ORDER BY id vs ORDER BY season 이 실제로 같은 순서를 의미하면 '동일'\n",
    "3. 만약 실제 결과가 다르다면, answer에 \"0\"을 적고 그 이유를 설명해 주세요.\n",
    "4. 답변은 아래 JSON 형식으로만 작성해 주세요 (다른 텍스트, 문장 포함 금지):\n",
    "- **\"answer\"**: \n",
    "  - \"1\"이면 두 쿼리가 의미적으로 동일한 결과를 반환한다는 의미\n",
    "  - \"0\"이면 의미적으로 다른 결과를 반환한다는 의미  \n",
    "- **\"explanation\"**: \n",
    "  - 왜 동일한지 또는 왜 다른지를 한글로 간단히 설명  \n",
    "  - 쿼리가 완전히 같은지, 컬럼명이 달라도 동일한 컬럼을 참조하고 있는지, GROUP BY 차이가 결과에 영향을 주는지/주지 않는지, etc. 상세히 기술\n",
    "\n",
    "### (예시) \n",
    "1. **(동일한 결과 예시)**  \n",
    "   - 쿼리 A: `SELECT \"Semifinalists\" FROM table_31066 WHERE \"Runner-up\" = 'Sammy Giammalva'`  \n",
    "   - 쿼리 B: `SELECT \"Semifinalists\" FROM table_31066 WHERE \"Runner-up\" = 'sammy zimmalva'`  \n",
    "   - 이 경우는 **Runner-up 이름이 전혀 다르므로 실제 결과가 다르다** → `answer: 0`  \n",
    "   \n",
    "2. **(동일한 결과 예시)**  \n",
    "   - 쿼리 A: `SELECT T1.CName FROM COURSE AS T1 JOIN ENROLLED_IN AS T2 ON T1.CID = T2.CID GROUP BY T2.CID HAVING COUNT(*) >= 5`  \n",
    "   - 쿼리 B: `SELECT T1.CName FROM COURSE T1 JOIN ENROLLED_IN T2 ON T1.CID = T2.CID GROUP BY T1.CName HAVING COUNT(*) >= 5`  \n",
    "   - 만약 `CName`과 `CID`가 1:1 대응되어 있어 실제 반환되는 행이 **동일**하다면 `answer=1`.  \n",
    "   - 만약 CName에 중복이 있을 수 있어 결과가 달라진다면 `answer=0`.\n",
    "\n",
    "3. **(동일한 결과 예시)**  \n",
    "   - 쿼리 A: `SELECT \"west\" FROM table_204_1 ORDER BY \"season\" DESC LIMIT 1`  \n",
    "   - 쿼리 B: `SELECT \"west\" FROM table_204_1 ORDER BY id DESC LIMIT 1`  \n",
    "   - 만약 `id`와 `\"season\"`이 완전히 같은 순으로 증가한다면 **결과가 같다** → `answer=1`.  \n",
    "   - 만약 그렇지 않다면(예: id가 엉뚱하게 매겨짐) → `answer=0`.\n",
    "\n",
    "위 사항을 참고하여, \n",
    "- **두 SQL 쿼리가 의미적으로 동일한지** (결과 집합이 같은지)  \n",
    "- 대소문자, 공백, 별칭 차이 등은 **결과에 영향을 주지 않으므로** `answer=1`로 처리  \n",
    "- 실제 결과가 다른 경우만 `answer=0` 처리하고 왜 다른지 짧게 설명  \n",
    "\n",
    "이 지침에 **엄격히** 따라 판단하십시오.\n",
    "\n",
    "    {{\n",
    "    \"answer\": \"1 또는 0\",\n",
    "    \"explanation\": \"이유를 한글로 간결히\"\n",
    "    }}\n",
    "\n",
    "    위 지침을 만족하도록 문제와 쿼리 정보를 참고해 판단해 주세요.\n",
    "\n",
    "    ----------------------------\n",
    "    문제 설명:\n",
    "    {problem_description}\n",
    "\n",
    "    생성된 쿼리:\n",
    "    {generated_query}\n",
    "\n",
    "    정답(원본) 쿼리:\n",
    "    {ground_truth_query}\n",
    "\n",
    "    판단 후, \n",
    "    - 두 쿼리가 의미적으로 동일하면 \"answer\": \"1\"\n",
    "    - 다르면 \"answer\": \"0\"\n",
    "    그리고 \"explanation\"에 그 이유를 한글로 적어주세요.\n",
    "    \"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        # Structured Output\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-mini\",  # 사용 가능한 모델로 변경\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"주어진 문제의 맥락에서 SQL 쿼리의 의미적 의미를 비교하는 유용한 도우미입니다. \"\n",
    "                        \"explanation은 한글로 작성하세요.\"\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            response_format=SqlComparisonResult,\n",
    "        )\n",
    "        parsed_result = completion.choices[0].message.parsed\n",
    "        \n",
    "        # dict로 변환\n",
    "        result_dict = {\n",
    "            \"index\": idx,\n",
    "            \"answer\": parsed_result.answer,\n",
    "            \"explanation\": parsed_result.explanation\n",
    "        }\n",
    "        # 파일로 저장\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(result_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # print(f\"[{idx}] Saved: answer={parsed_result.answer}\")\n",
    "        return result_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{idx}] Error processing: {e}\")\n",
    "        return {\n",
    "            \"index\": idx,\n",
    "            \"answer\": -1,\n",
    "            \"explanation\": f\"Error: {str(e)}\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01afdbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 1234/1234 [00:00<00:00, 15861.13it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 1234/1234 [04:30<00:00,  4.56it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 1234/1234 [00:00<00:00, 206543.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OpenAI 검증] 의미적으로 동일(1): 342, 다름(0): 892, 총 1234개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. pqdm을 이용한 병렬 처리\n",
    "# ------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    from pqdm.processes import pqdm\n",
    "\n",
    "    # 병렬 처리 (CPU core 개수에 맞춰 n_jobs 조정)\n",
    "    results = pqdm(differing_items, one_compare_sql_semantics, n_jobs=5)\n",
    "\n",
    "    # 2차 검증 결과 중 answer가 1인 것(의미적으로 동일하다고 판정)\n",
    "    # => 몇 개나 되는지 집계\n",
    "    valid_results = [r for r in results if r[\"answer\"] in (0,1)]\n",
    "    if len(valid_results) == 0:\n",
    "        print(\"\\n[OpenAI 검증] 유효 결과가 없습니다.\")\n",
    "    else:\n",
    "        semantically_same = sum(r[\"answer\"] == 1 for r in valid_results)\n",
    "        semantically_diff = sum(r[\"answer\"] == 0 for r in valid_results)\n",
    "        print(f\"\\n[OpenAI 검증] 의미적으로 동일(1): {semantically_same}, \"\n",
    "              f\"다름(0): {semantically_diff}, 총 {len(valid_results)}개\")\n",
    "\n",
    "\n",
    "    # 참고) 이후에는 '의미적 동일(=1)'인 케이스가 얼마나 되는지\n",
    "    #      추가 통계(Overall Accuracy 등)도 계산할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3e40a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답 개수: 342/1234 개 (정확도: 27.71%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# 결과가 저장된 폴더\n",
    "save_folder = Path(\"/root/workspace/text_to_sql/openai_result_qwen2.5_all-en\")\n",
    "\n",
    "# 파일 목록 가져오기\n",
    "json_files = sorted(save_folder.glob(\"result_*.json\"))\n",
    "\n",
    "num_files = 0\n",
    "num_correct = 0\n",
    "\n",
    "for file_path in json_files:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        # data 형태 예시:\n",
    "        # {\n",
    "        #   \"answer\": 1,\n",
    "        #   \"explanation\": \"...\"\n",
    "        # }\n",
    "        \n",
    "        # answer가 1이면 \"의미적으로 동일\"이라고 판단한 것이므로 맞았다고 봄\n",
    "        if data.get(\"answer\") == 1:\n",
    "            num_correct += 1\n",
    "        num_files += 1\n",
    "\n",
    "# 간단한 통계\n",
    "if num_files > 0:\n",
    "    accuracy = (num_correct / num_files) * 100\n",
    "    print(f\"정답 개수: {num_correct}/{num_files} 개 (정확도: {accuracy:.2f}%)\")\n",
    "else:\n",
    "    print(\"결과 파일이 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dc2afe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 82.99%\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = (sum(generated_result) + num_correct) / len(generated_result) * 100\n",
    "print(f\"정확도 : {total_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_to_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
