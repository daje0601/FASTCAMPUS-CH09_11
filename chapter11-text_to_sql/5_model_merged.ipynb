{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f640f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/root/workspace/text_to_sql/merged_qwen2.5-all-en/tokenizer_config.json',\n",
       " '/root/workspace/text_to_sql/merged_qwen2.5-all-en/special_tokens_map.json',\n",
       " '/root/workspace/text_to_sql/merged_qwen2.5-all-en/vocab.json',\n",
       " '/root/workspace/text_to_sql/merged_qwen2.5-all-en/merges.txt',\n",
       " '/root/workspace/text_to_sql/merged_qwen2.5-all-en/added_tokens.json',\n",
       " '/root/workspace/text_to_sql/merged_qwen2.5-all-en/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 기본 설정\n",
    "base_model_id = \"Qwen/Qwen2.5-Coder-7B-Instruct\"  # 기본 모델 경로 또는 HF 모델명\n",
    "adapter_path = \"./Qwen2.5-all-en/checkpoint-128481\"      # LoRA 어댑터 경로\n",
    "merged_path = \"./merged_qwen2.5-all-en\"       # 저장할 경로\n",
    "\n",
    "# 베이스 모델 로드\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "# PEFT 모델 로드 및 병합\n",
    "peft_model = PeftModel.from_pretrained(model, adapter_path)\n",
    "merged_model = peft_model.merge_and_unload()\n",
    "\n",
    "# 병합된 모델 저장\n",
    "merged_model.save_pretrained(\n",
    "    merged_path,\n",
    "    safe_serialization=True,\n",
    "    max_shard_size=\"5GB\"\n",
    ")\n",
    "\n",
    "# 토크나이저 저장\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "tokenizer.save_pretrained(merged_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# (1) 병합된 모델 다시 로드\n",
    "merged_model = AutoModelForCausalLM.from_pretrained(merged_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(merged_path)\n",
    "\n",
    "# (2) push_to_hub\n",
    "merged_model.push_to_hub(\"daje/Qwen2.5-coder-7B-en-all-merged\")   # 원하는 레포 이름\n",
    "tokenizer.push_to_hub(\"daje/Qwen2.5-coder-7B-en-all-merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2fc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_to_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
