{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.4.1+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import json_repair\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "from pqdm.processes import pqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "import trl\n",
    "import torch\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "from peft import LoraConfig, AutoPeftModelForCausalLM\n",
    "\n",
    "import wandb\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForCausalLM,\n",
    "                          BitsAndBytesConfig,\n",
    "                          TrainingArguments,\n",
    "                          pipeline)\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# # 환경변수 로드\n",
    "# load_dotenv(\"./credit-env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version       : 2.4.1+cu124\n",
      "Transformers version  : 4.51.2\n",
      "TRL version           : 0.16.1\n",
      "CUDA available        : True\n",
      "CUDA version      : 12.4\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version       : {torch.__version__}\")\n",
    "print(f\"Transformers version  : {transformers.__version__}\")\n",
    "print(f\"TRL version           : {trl.__version__}\")\n",
    "print(f\"CUDA available        : {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version      : {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7804afaefda420b95bbf5b4679f566d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06d17aedba643ffa720ba918bbaaa73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5d2685278348deb3c2315ae42f4b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'response', 'source', 'text', 'total_length', '__index_level_0__', 'translated_instruction', 'new_input'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = \"daje/kotext-to-sql-v1-hard\"\n",
    "dataset = load_dataset(data_name, split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5a0b865a994b3f8b34a859f267037a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ab81dc55e6411ba77d1c149502ce79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/47.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81094a81301f491f92b5b6e28356c099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd76fc087c844c595f8393bdb8f5f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00006.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e46ee7a27c45e09b25db075c9a41c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00006.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdcf57afdce4122b93f62bd8766c2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00006.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d554ca1c504539b65d74607d9307dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00006.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46c7a0701fc4e67bf43d83aeb9c334c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00006.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4619143b7f6947d4b64bb1ff1829aff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00006.safetensors:   0%|          | 0.00/4.73G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fc0c95b6b7435abc601dc1cdf0597e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a103533162f423ba3182f271a3845c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc19f27386124f598747ab16b4254360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfd00d0d0634413bb880066f2a521c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfee9f12791a40c3883da2cff9de7573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241e146beed64647ae9e746caa66dae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 제로샷 테스트를 하기 위해 모델을 다운받고, 인퍼런스를 실행합니다. \n",
    "model_name = \"Qwen/Qwen2.5-Coder-14B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": 'Task:라틴 아메리카/카리브해 지역의 인구가 783(7.5%)가 될 때, 아시아의 인구는 얼마가 될까요?\\nSQL Table:CREATE TABLE table_22767 (\\n    \"Year\" real,\\n    \"World\" real,\\n    \"Asia\" text,\\n    \"Africa\" text,\\n    \"Europe\" text,\\n    \"Latin America/Caribbean\" text,\\n    \"Northern America\" text,\\n    \"Oceania\" text\\n)\\nQuery:'}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'response', 'source', 'text', 'total_length', '__index_level_0__', 'translated_instruction', 'new_input'],\n",
       "        num_rows: 1800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'response', 'source', 'text', 'total_length', '__index_level_0__', 'translated_instruction', 'new_input'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Which requirements do I need to meet for a CS-LSA degree ?',\n",
       " 'input': 'CREATE TABLE program_course (\\n    program_id int,\\n    course_id int,\\n    workload int,\\n    category varchar\\n)\\n\\nCREATE TABLE course_tags_count (\\n    course_id int,\\n    clear_grading int,\\n    pop_quiz int,\\n    group_projects int,\\n    inspirational int,\\n    long_lectures int,\\n    extra_credit int,\\n    few_tests int,\\n    good_feedback int,\\n    tough_tests int,\\n    heavy_papers int,\\n    cares_for_students int,\\n    heavy_assignments int,\\n    respected int,\\n    participation int,\\n    heavy_reading int,\\n    tough_grader int,\\n    hilarious int,\\n    would_take_again int,\\n    good_lecture int,\\n    no_skip int\\n)\\n\\nCREATE TABLE jobs (\\n    job_id int,\\n    job_title varchar,\\n    description varchar,\\n    requirement varchar,\\n    city varchar,\\n    state varchar,\\n    country varchar,\\n    zip int\\n)\\n\\nCREATE TABLE student_record (\\n    student_id int,\\n    course_id int,\\n    semester int,\\n    grade varchar,\\n    how varchar,\\n    transfer_source varchar,\\n    earn_credit varchar,\\n    repeat_term varchar,\\n    test_id varchar\\n)\\n\\nCREATE TABLE course_offering (\\n    offering_id int,\\n    course_id int,\\n    semester int,\\n    section_number int,\\n    start_time time,\\n    end_time time,\\n    monday varchar,\\n    tuesday varchar,\\n    wednesday varchar,\\n    thursday varchar,\\n    friday varchar,\\n    saturday varchar,\\n    sunday varchar,\\n    has_final_project varchar,\\n    has_final_exam varchar,\\n    textbook varchar,\\n    class_address varchar,\\n    allow_audit varchar\\n)\\n\\nCREATE TABLE ta (\\n    campus_job_id int,\\n    student_id int,\\n    location varchar\\n)\\n\\nCREATE TABLE program_requirement (\\n    program_id int,\\n    category varchar,\\n    min_credit int,\\n    additional_req varchar\\n)\\n\\nCREATE TABLE comment_instructor (\\n    instructor_id int,\\n    student_id int,\\n    score int,\\n    comment_text varchar\\n)\\n\\nCREATE TABLE semester (\\n    semester_id int,\\n    semester varchar,\\n    year int\\n)\\n\\nCREATE TABLE course_prerequisite (\\n    pre_course_id int,\\n    course_id int\\n)\\n\\nCREATE TABLE instructor (\\n    instructor_id int,\\n    name varchar,\\n    uniqname varchar\\n)\\n\\nCREATE TABLE student (\\n    student_id int,\\n    lastname varchar,\\n    firstname varchar,\\n    program_id int,\\n    declare_major varchar,\\n    total_credit int,\\n    total_gpa float,\\n    entered_as varchar,\\n    admit_term int,\\n    predicted_graduation_semester int,\\n    degree varchar,\\n    minor varchar,\\n    internship varchar\\n)\\n\\nCREATE TABLE program (\\n    program_id int,\\n    name varchar,\\n    college varchar,\\n    introduction varchar\\n)\\n\\nCREATE TABLE requirement (\\n    requirement_id int,\\n    requirement varchar,\\n    college varchar\\n)\\n\\nCREATE TABLE course (\\n    course_id int,\\n    name varchar,\\n    department varchar,\\n    number varchar,\\n    credits varchar,\\n    advisory_requirement varchar,\\n    enforced_requirement varchar,\\n    description varchar,\\n    num_semesters int,\\n    num_enrolled int,\\n    has_discussion varchar,\\n    has_lab varchar,\\n    has_projects varchar,\\n    has_exams varchar,\\n    num_reviews int,\\n    clarity_score int,\\n    easiness_score int,\\n    helpfulness_score int\\n)\\n\\nCREATE TABLE offering_instructor (\\n    offering_instructor_id int,\\n    offering_id int,\\n    instructor_id int\\n)\\n\\nCREATE TABLE area (\\n    course_id int,\\n    area varchar\\n)\\n\\nCREATE TABLE gsi (\\n    course_offering_id int,\\n    student_id int\\n)',\n",
       " 'response': \"SELECT DISTINCT program_requirement.additional_req, program_requirement.category, program_requirement.min_credit, program.name FROM program, program_requirement WHERE program.name LIKE '%CS-LSA%' AND program.program_id = program_requirement.program_id\",\n",
       " 'source': 'advising',\n",
       " 'text': \"Below are sql tables schemas paired with instruction that describes a task. Using valid SQLite, write a response that appropriately completes the request for the provided tables. ### Instruction: Which requirements do I need to meet for a CS-LSA degree ? ### Input: CREATE TABLE program_course (\\n    program_id int,\\n    course_id int,\\n    workload int,\\n    category varchar\\n)\\n\\nCREATE TABLE course_tags_count (\\n    course_id int,\\n    clear_grading int,\\n    pop_quiz int,\\n    group_projects int,\\n    inspirational int,\\n    long_lectures int,\\n    extra_credit int,\\n    few_tests int,\\n    good_feedback int,\\n    tough_tests int,\\n    heavy_papers int,\\n    cares_for_students int,\\n    heavy_assignments int,\\n    respected int,\\n    participation int,\\n    heavy_reading int,\\n    tough_grader int,\\n    hilarious int,\\n    would_take_again int,\\n    good_lecture int,\\n    no_skip int\\n)\\n\\nCREATE TABLE jobs (\\n    job_id int,\\n    job_title varchar,\\n    description varchar,\\n    requirement varchar,\\n    city varchar,\\n    state varchar,\\n    country varchar,\\n    zip int\\n)\\n\\nCREATE TABLE student_record (\\n    student_id int,\\n    course_id int,\\n    semester int,\\n    grade varchar,\\n    how varchar,\\n    transfer_source varchar,\\n    earn_credit varchar,\\n    repeat_term varchar,\\n    test_id varchar\\n)\\n\\nCREATE TABLE course_offering (\\n    offering_id int,\\n    course_id int,\\n    semester int,\\n    section_number int,\\n    start_time time,\\n    end_time time,\\n    monday varchar,\\n    tuesday varchar,\\n    wednesday varchar,\\n    thursday varchar,\\n    friday varchar,\\n    saturday varchar,\\n    sunday varchar,\\n    has_final_project varchar,\\n    has_final_exam varchar,\\n    textbook varchar,\\n    class_address varchar,\\n    allow_audit varchar\\n)\\n\\nCREATE TABLE ta (\\n    campus_job_id int,\\n    student_id int,\\n    location varchar\\n)\\n\\nCREATE TABLE program_requirement (\\n    program_id int,\\n    category varchar,\\n    min_credit int,\\n    additional_req varchar\\n)\\n\\nCREATE TABLE comment_instructor (\\n    instructor_id int,\\n    student_id int,\\n    score int,\\n    comment_text varchar\\n)\\n\\nCREATE TABLE semester (\\n    semester_id int,\\n    semester varchar,\\n    year int\\n)\\n\\nCREATE TABLE course_prerequisite (\\n    pre_course_id int,\\n    course_id int\\n)\\n\\nCREATE TABLE instructor (\\n    instructor_id int,\\n    name varchar,\\n    uniqname varchar\\n)\\n\\nCREATE TABLE student (\\n    student_id int,\\n    lastname varchar,\\n    firstname varchar,\\n    program_id int,\\n    declare_major varchar,\\n    total_credit int,\\n    total_gpa float,\\n    entered_as varchar,\\n    admit_term int,\\n    predicted_graduation_semester int,\\n    degree varchar,\\n    minor varchar,\\n    internship varchar\\n)\\n\\nCREATE TABLE program (\\n    program_id int,\\n    name varchar,\\n    college varchar,\\n    introduction varchar\\n)\\n\\nCREATE TABLE requirement (\\n    requirement_id int,\\n    requirement varchar,\\n    college varchar\\n)\\n\\nCREATE TABLE course (\\n    course_id int,\\n    name varchar,\\n    department varchar,\\n    number varchar,\\n    credits varchar,\\n    advisory_requirement varchar,\\n    enforced_requirement varchar,\\n    description varchar,\\n    num_semesters int,\\n    num_enrolled int,\\n    has_discussion varchar,\\n    has_lab varchar,\\n    has_projects varchar,\\n    has_exams varchar,\\n    num_reviews int,\\n    clarity_score int,\\n    easiness_score int,\\n    helpfulness_score int\\n)\\n\\nCREATE TABLE offering_instructor (\\n    offering_instructor_id int,\\n    offering_id int,\\n    instructor_id int\\n)\\n\\nCREATE TABLE area (\\n    course_id int,\\n    area varchar\\n)\\n\\nCREATE TABLE gsi (\\n    course_offering_id int,\\n    student_id int\\n) ### Response: SELECT DISTINCT program_requirement.additional_req, program_requirement.category, program_requirement.min_credit, program.name FROM program, program_requirement WHERE program.name LIKE '%CS-LSA%' AND program.program_id = program_requirement.program_id\",\n",
       " 'total_length': 367,\n",
       " '__index_level_0__': 1394,\n",
       " 'translated_instruction': 'CS-LSA 학위를 받기 위해 충족해야 하는 요구 사항은 무엇인가요?',\n",
       " 'new_input': '다음은 SQL 테이블 스키마와 수행할 작업에 대한 설명입니다. SQLite 문법에 맞는 쿼리만 작성해주세요. 설명이나 주석 없이 실행 가능한 SQL 쿼리 코드만 출력하세요.\\n### Instruction: CS-LSA 학위를 받기 위해 충족해야 하는 요구 사항은 무엇인가요?\\n### Input: CREATE TABLE program_course (\\n    program_id int,\\n    course_id int,\\n    workload int,\\n    category varchar\\n)\\n\\nCREATE TABLE course_tags_count (\\n    course_id int,\\n    clear_grading int,\\n    pop_quiz int,\\n    group_projects int,\\n    inspirational int,\\n    long_lectures int,\\n    extra_credit int,\\n    few_tests int,\\n    good_feedback int,\\n    tough_tests int,\\n    heavy_papers int,\\n    cares_for_students int,\\n    heavy_assignments int,\\n    respected int,\\n    participation int,\\n    heavy_reading int,\\n    tough_grader int,\\n    hilarious int,\\n    would_take_again int,\\n    good_lecture int,\\n    no_skip int\\n)\\n\\nCREATE TABLE jobs (\\n    job_id int,\\n    job_title varchar,\\n    description varchar,\\n    requirement varchar,\\n    city varchar,\\n    state varchar,\\n    country varchar,\\n    zip int\\n)\\n\\nCREATE TABLE student_record (\\n    student_id int,\\n    course_id int,\\n    semester int,\\n    grade varchar,\\n    how varchar,\\n    transfer_source varchar,\\n    earn_credit varchar,\\n    repeat_term varchar,\\n    test_id varchar\\n)\\n\\nCREATE TABLE course_offering (\\n    offering_id int,\\n    course_id int,\\n    semester int,\\n    section_number int,\\n    start_time time,\\n    end_time time,\\n    monday varchar,\\n    tuesday varchar,\\n    wednesday varchar,\\n    thursday varchar,\\n    friday varchar,\\n    saturday varchar,\\n    sunday varchar,\\n    has_final_project varchar,\\n    has_final_exam varchar,\\n    textbook varchar,\\n    class_address varchar,\\n    allow_audit varchar\\n)\\n\\nCREATE TABLE ta (\\n    campus_job_id int,\\n    student_id int,\\n    location varchar\\n)\\n\\nCREATE TABLE program_requirement (\\n    program_id int,\\n    category varchar,\\n    min_credit int,\\n    additional_req varchar\\n)\\n\\nCREATE TABLE comment_instructor (\\n    instructor_id int,\\n    student_id int,\\n    score int,\\n    comment_text varchar\\n)\\n\\nCREATE TABLE semester (\\n    semester_id int,\\n    semester varchar,\\n    year int\\n)\\n\\nCREATE TABLE course_prerequisite (\\n    pre_course_id int,\\n    course_id int\\n)\\n\\nCREATE TABLE instructor (\\n    instructor_id int,\\n    name varchar,\\n    uniqname varchar\\n)\\n\\nCREATE TABLE student (\\n    student_id int,\\n    lastname varchar,\\n    firstname varchar,\\n    program_id int,\\n    declare_major varchar,\\n    total_credit int,\\n    total_gpa float,\\n    entered_as varchar,\\n    admit_term int,\\n    predicted_graduation_semester int,\\n    degree varchar,\\n    minor varchar,\\n    internship varchar\\n)\\n\\nCREATE TABLE program (\\n    program_id int,\\n    name varchar,\\n    college varchar,\\n    introduction varchar\\n)\\n\\nCREATE TABLE requirement (\\n    requirement_id int,\\n    requirement varchar,\\n    college varchar\\n)\\n\\nCREATE TABLE course (\\n    course_id int,\\n    name varchar,\\n    department varchar,\\n    number varchar,\\n    credits varchar,\\n    advisory_requirement varchar,\\n    enforced_requirement varchar,\\n    description varchar,\\n    num_semesters int,\\n    num_enrolled int,\\n    has_discussion varchar,\\n    has_lab varchar,\\n    has_projects varchar,\\n    has_exams varchar,\\n    num_reviews int,\\n    clarity_score int,\\n    easiness_score int,\\n    helpfulness_score int\\n)\\n\\nCREATE TABLE offering_instructor (\\n    offering_instructor_id int,\\n    offering_id int,\\n    instructor_id int\\n)\\n\\nCREATE TABLE area (\\n    course_id int,\\n    area varchar\\n)\\n\\nCREATE TABLE gsi (\\n    course_offering_id int,\\n    student_id int\\n)\\n'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7889b702674dae9435d8e5e170c59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_chat_format(element):\n",
    "    system_prompt = \"너는 주어진 Schema와 Question을 보고 하는 SQL을 생성하는 AI Asisstant입니다.\"\n",
    "    user_prompt = f\"### instruction:{element['translated_instruction']} ### input:{element['input']} ### response:\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "            {\"role\": \"assistant\", \"content\": element[\"response\"]+tokenizer.eos_token},  # 여기 닫는 괄호 추가\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# train과 test 데이터를 0.9와 0.1로 분할합니다.\n",
    "dataset_train = dataset[\"train\"].map(\n",
    "    get_chat_format,\n",
    "    batched=False,\n",
    "    remove_columns=dataset[\"train\"].features,  # 원하시면 제거\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 1800\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '너는 주어진 Schema와 Question을 보고 하는 SQL을 생성하는 AI Asisstant입니다.',\n",
       "  'role': 'system'},\n",
       " {'content': '### instruction:CS-LSA 학위를 받기 위해 충족해야 하는 요구 사항은 무엇인가요? ### input:CREATE TABLE program_course (\\n    program_id int,\\n    course_id int,\\n    workload int,\\n    category varchar\\n)\\n\\nCREATE TABLE course_tags_count (\\n    course_id int,\\n    clear_grading int,\\n    pop_quiz int,\\n    group_projects int,\\n    inspirational int,\\n    long_lectures int,\\n    extra_credit int,\\n    few_tests int,\\n    good_feedback int,\\n    tough_tests int,\\n    heavy_papers int,\\n    cares_for_students int,\\n    heavy_assignments int,\\n    respected int,\\n    participation int,\\n    heavy_reading int,\\n    tough_grader int,\\n    hilarious int,\\n    would_take_again int,\\n    good_lecture int,\\n    no_skip int\\n)\\n\\nCREATE TABLE jobs (\\n    job_id int,\\n    job_title varchar,\\n    description varchar,\\n    requirement varchar,\\n    city varchar,\\n    state varchar,\\n    country varchar,\\n    zip int\\n)\\n\\nCREATE TABLE student_record (\\n    student_id int,\\n    course_id int,\\n    semester int,\\n    grade varchar,\\n    how varchar,\\n    transfer_source varchar,\\n    earn_credit varchar,\\n    repeat_term varchar,\\n    test_id varchar\\n)\\n\\nCREATE TABLE course_offering (\\n    offering_id int,\\n    course_id int,\\n    semester int,\\n    section_number int,\\n    start_time time,\\n    end_time time,\\n    monday varchar,\\n    tuesday varchar,\\n    wednesday varchar,\\n    thursday varchar,\\n    friday varchar,\\n    saturday varchar,\\n    sunday varchar,\\n    has_final_project varchar,\\n    has_final_exam varchar,\\n    textbook varchar,\\n    class_address varchar,\\n    allow_audit varchar\\n)\\n\\nCREATE TABLE ta (\\n    campus_job_id int,\\n    student_id int,\\n    location varchar\\n)\\n\\nCREATE TABLE program_requirement (\\n    program_id int,\\n    category varchar,\\n    min_credit int,\\n    additional_req varchar\\n)\\n\\nCREATE TABLE comment_instructor (\\n    instructor_id int,\\n    student_id int,\\n    score int,\\n    comment_text varchar\\n)\\n\\nCREATE TABLE semester (\\n    semester_id int,\\n    semester varchar,\\n    year int\\n)\\n\\nCREATE TABLE course_prerequisite (\\n    pre_course_id int,\\n    course_id int\\n)\\n\\nCREATE TABLE instructor (\\n    instructor_id int,\\n    name varchar,\\n    uniqname varchar\\n)\\n\\nCREATE TABLE student (\\n    student_id int,\\n    lastname varchar,\\n    firstname varchar,\\n    program_id int,\\n    declare_major varchar,\\n    total_credit int,\\n    total_gpa float,\\n    entered_as varchar,\\n    admit_term int,\\n    predicted_graduation_semester int,\\n    degree varchar,\\n    minor varchar,\\n    internship varchar\\n)\\n\\nCREATE TABLE program (\\n    program_id int,\\n    name varchar,\\n    college varchar,\\n    introduction varchar\\n)\\n\\nCREATE TABLE requirement (\\n    requirement_id int,\\n    requirement varchar,\\n    college varchar\\n)\\n\\nCREATE TABLE course (\\n    course_id int,\\n    name varchar,\\n    department varchar,\\n    number varchar,\\n    credits varchar,\\n    advisory_requirement varchar,\\n    enforced_requirement varchar,\\n    description varchar,\\n    num_semesters int,\\n    num_enrolled int,\\n    has_discussion varchar,\\n    has_lab varchar,\\n    has_projects varchar,\\n    has_exams varchar,\\n    num_reviews int,\\n    clarity_score int,\\n    easiness_score int,\\n    helpfulness_score int\\n)\\n\\nCREATE TABLE offering_instructor (\\n    offering_instructor_id int,\\n    offering_id int,\\n    instructor_id int\\n)\\n\\nCREATE TABLE area (\\n    course_id int,\\n    area varchar\\n)\\n\\nCREATE TABLE gsi (\\n    course_offering_id int,\\n    student_id int\\n) ### response:',\n",
       "  'role': 'user'},\n",
       " {'content': \"SELECT DISTINCT program_requirement.additional_req, program_requirement.category, program_requirement.min_credit, program.name FROM program, program_requirement WHERE program.name LIKE '%CS-LSA%' AND program.program_id = program_requirement.program_id<|im_end|>\",\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[\"messages\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Task:라틴 아메리카/카리브해 지역의 인구가 783(7.5%)가 될 때, 아시아의 인구는 얼마가 될까요?\n",
      "SQL Table:CREATE TABLE table_22767 (\n",
      "    \"Year\" real,\n",
      "    \"World\" real,\n",
      "    \"Asia\" text,\n",
      "    \"Africa\" text,\n",
      "    \"Europe\" text,\n",
      "    \"Latin America/Caribbean\" text,\n",
      "    \"Northern America\" text,\n",
      "    \"Oceania\" text\n",
      ")\n",
      "Query:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "response_template = \"<|im_start|>assistant\\n\"\n",
    "# 만약 실제로 줄바꿈까지 포함되어 있다면 \\n까지 넣어줘야 합니다.\n",
    "# response_template = \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "\n",
    "response_template_ids = tokenizer.encode(response_template, add_special_tokens=False)\n",
    "collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template_ids,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c9e74e61c24eb88b61b464b0164088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee6f2bb211947bbbf1ae859c7b502a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b1aeb582584455911bcb759bfd0407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540b662a93ed4d67b7db0289bec0a84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "        lora_alpha=64,                            \n",
    "        lora_dropout=0.05,                         # Lora 학습 때 사용할 dropout 확률을 지정합니다. 드롭아웃 확률은 과적합 방지를 위해 학습 중 무작위로 일부 뉴런을 비활성화하는 비율을 지정합니다.\n",
    "        r=64,                                     # Lora의 저차원 공간의 랭크를 지정합니다. 랭크가 높을수록 모델의 표현력이 증가하지만, 계산 비용도 증가합니다.\n",
    "        bias=\"none\",                               # Lora 적용 시 바이어스를 사용할지 여부를 설정합니다. \"none\"으로 설정하면 바이어스를 사용하지 않습니다.\n",
    "        target_modules=[\"q_proj\", \"o_proj\",        # Lora를 적용할 모델의 모듈 리스트입니다.\n",
    "                        \"k_proj\", \"v_proj\"\n",
    "                        \"up_proj\", \"down_proj\",\n",
    "                        \"gate_proj\",\n",
    "                        ],\n",
    "        task_type=\"CAUSAL_LM\",                     # 미세 조정 작업 유형을 CAUSAL_LM으로 지정하여 언어 모델링 작업을 수행합니다.\n",
    ")\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output_train1\", # 모델 저장 및 허브 업로드를 위한 디렉토리 지정 합니다.\n",
    "    num_train_epochs=5,                     # number of training epochs\n",
    "    # max_steps=100,                        # 100스텝 동안 훈련 수행합니다.\n",
    "    per_device_train_batch_size=2,          # 배치 사이즈 설정 합니다.\n",
    "    gradient_accumulation_steps=2,          # 2스텝마다 역전파 및 가중치 업데이트합니다.\n",
    "    gradient_checkpointing=False,           # 메모리 절약을 위해 그래디언트 체크포인팅 사용합니다.\n",
    "    optim=\"adamw_torch_fused\",              # 메모리 효율화할 수 있는 fused AdamW 옵티마이저 사용합니다.\n",
    "    logging_steps=50,                       # 10스텝마다 로그 기록합니다.\n",
    "    save_strategy=\"steps\",                  # 매 에폭마다 체크포인트 저장합니다.\n",
    "    learning_rate=5e-5,                     # 학습률 2e-4로 설정 (QLoRA 논문 기반)합니다.\n",
    "    bf16=True,                              # 정밀도 설정으로 학습 속도 향상합니다.\n",
    "    tf32=True,\n",
    "    max_grad_norm=0.3,                      # 그래디언트 클리핑 값 0.3으로 설정합니다.\n",
    "    warmup_ratio=0.03,                      # 워밍업 비율 0.03으로 설정 (QLoRA 논문 기반)합니다.\n",
    "    lr_scheduler_type=\"constant\",# 일정한 학습률 스케줄러 사용합니다.\n",
    "    push_to_hub=False,                      # 훈련된 모델을 Hugging Face Hub에 업로드합니다.\n",
    "    report_to=\"none\",                       # wandb로 매트릭 관찰합니다.\n",
    ")\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset_train,\n",
    "    peft_config=peft_config,\n",
    "    # tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2250/2250 1:31:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.486400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.090300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.079500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.066700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.033700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.047600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.036400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.037700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.039200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.014800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.019400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.007700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.008100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2250, training_loss=0.044881479375892215, metrics={'train_runtime': 5507.6165, 'train_samples_per_second': 1.634, 'train_steps_per_second': 0.409, 'total_flos': 7.626520275526164e+17, 'train_loss': 0.044881479375892215})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer를 학습합니다.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"output_train1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 초기화\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8697f2b704204c5ca8141157e8727f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습한 모델을 경로를 지정합니다.\n",
    "save_dir = \"/workspace/output_train1\"\n",
    "peft_model_id = f\"{save_dir}\"\n",
    "\n",
    "# PEFT 어댑터를 통해 사전 학습된 모델을 로드합니다.\n",
    "fine_tuned_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "  peft_model_id,\n",
    "  device_map=\"auto\",\n",
    "  torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "# 토크나이저 로드합니다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
    "tokenizer.padding_side = 'right'  \n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587f8921b79e42e4afa0922d7c012c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_chat_format_inference(element):\n",
    "    system_prompt = \"너는 주어진 Schema와 Question을 보고 하는 SQL을 생성하는 AI Asisstant입니다.\"\n",
    "    user_prompt = f\"### instruction:{element['translated_instruction']} ### input:{element['input']} ### response:\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def apply_chat_format_inference(element):\n",
    "    \"\"\"\n",
    "    1) get_chat_format_inference(element)를 호출해서\n",
    "       messages를 생성한 뒤, Dataset에 저장할 dict로 반환합니다.\n",
    "    \"\"\"\n",
    "    chat_format = get_chat_format_inference(element)  # get_chat_format은 원본 코드 그대로 사용\n",
    "    return {\n",
    "        \"messages\": chat_format[\"messages\"]\n",
    "    }\n",
    "\n",
    "\n",
    "# train과 test 데이터를 0.9와 0.1로 분할합니다.\n",
    "dataset_test = dataset[\"test\"].map(\n",
    "    apply_chat_format_inference,\n",
    "    batched=False,\n",
    "    remove_columns=dataset[\"test\"].features,  # 원하시면 제거\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24d440a249e43a69084280c6f404a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "output_list = []    \n",
    "for idx in tqdm(range(len(dataset_test))):\n",
    "    input_data = tokenizer.apply_chat_template(dataset_test[idx][\"messages\"], tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(input_data, return_tensors=\"pt\").to(\"cuda\")\n",
    "    result = fine_tuned_model.generate(\n",
    "            **inputs,                      # 토큰화된 입력 전달\n",
    "            max_new_tokens=512,            # 생성할 최대 토큰 개수 설정\n",
    "            temperature=0.1,               # 낮은 temperature로 예측 결과의 랜덤성을 낮춤 (결과가 일관됨)\n",
    "            pad_token_id=tokenizer.eos_token_id  # 문장 끝을 나타내는 토큰 설정 (패딩 방지)\n",
    "        )\n",
    "    output = tokenizer.decode(\n",
    "            result[0][len(inputs.input_ids[0]):],  # 입력 부분 토큰을 제외한 생성된 부분만 추출\n",
    "            skip_special_tokens=True               # 특수 토큰을 제외하고 텍스트 변환\n",
    "        )\n",
    "    output_list.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT d_icd_procedures.short_title FROM d_icd_procedures WHERE d_icd_procedures.icd9_code IN (SELECT t3.icd9_code FROM (SELECT t2.icd9_code, DENSE_RANK() OVER (ORDER BY COUNT(*) DESC) AS c1 FROM (SELECT admissions.subject_id, diagnoses_icd.charttime FROM diagnoses_icd JOIN admissions ON diagnoses_icd.hadm_id = admissions.hadm_id WHERE diagnoses_icd.icd9_code = (SELECT d_icd_diagnoses.icd9_code FROM d_icd_diagnoses WHERE d_icd_diagnoses.short_title = 'malignant melanoma') AND DATETIME(diagnoses_icd.charttime) >= DATETIME(CURRENT_TIME(), '-5 year')) AS t1 JOIN (SELECT admissions.subject_id, procedures_icd.icd9_code, procedures_icd.charttime FROM procedures_icd JOIN admissions ON procedures_icd.hadm_id = admissions.hadm_id WHERE DATETIME(procedures_icd.charttime) >= DATETIME(CURRENT_TIME(), '-5 year')) AS t2 ON t1.subject_id = t2.subject_id WHERE t1.charttime < t2.charttime AND DATETIME(t2.charttime) <= DATETIME(t1.charttime, '+2 month') GROUP BY t2.icd9_code) AS t3 WHERE t3.c1 <= 4)\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_input = [temp[1][\"content\"] for temp in dataset_test[\"messages\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame({\n",
    "    \"inputs\":dataset_test_input,\n",
    "    \"answers\": dataset[\"test\"][\"response\"],\n",
    "    \"predictions\":output_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs         ### instruction:항공편이 BOSTON에서 DENVER로 가는 항공사를 ...\n",
       "answers        SELECT DISTINCT airline.airline_code FROM airl...\n",
       "predictions    SELECT DISTINCT airline.airline_code FROM airl...\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"./credit-env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1cb6001c9347fb9f72d2c7eaa8eb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97bbe04368340bebef046af00a23747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f778bf890344b5beea2536d2c5f3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel \n",
    "\n",
    "class json_output(BaseModel):\n",
    "    reason: str\n",
    "    score: bool\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "def evaluation_log(args):\n",
    "    df, idx = args\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=f\"\"\"너는 주어진 SQL system prompt와 내가 만든 model이 SQL system prompt를 보고 만든 생성결과와 실제 정답을 너에게 전달해줄게. 이를 보고 모델이 알맞게 예측하였는지 평가하는 AI Asisstant입니다.\n",
    "# SQL system prompt\n",
    "{df['inputs'].iloc[idx]}\n",
    "# model 생성결과\n",
    "{df['predictions'].iloc[idx]}\n",
    "# 실제 정답\n",
    "{df['answers'].iloc[idx]}\n",
    "\n",
    "# 평가 기준\n",
    "- reason은 한국어로 작성하세요.\n",
    "-score는 모델이 의미적으로 같은 결과를 조회하는 쿼리라면 True, 아니면 False로 평가하세요.\n",
    "\"\"\",\n",
    "        config=types.GenerateContentConfig(\n",
    "        max_output_tokens=1000,  # Set the desired maximum number of output tokens\n",
    "        temperature=0.0,\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=json_output,\n",
    "        ),\n",
    "    )\n",
    "    model_response = response.candidates[0].content.parts[0].text\n",
    "    return model_response\n",
    "\n",
    "from pqdm.processes import pqdm\n",
    "args_list = [(final_df, idx) for idx in range(len(final_df))]\n",
    "prediction_eval_result = pqdm(args_list, evaluation_log, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reason</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>모델 생성 결과는 질문이 작성된 날짜와 답변이 채택된 날짜 사이의 일수를 구하는 쿼...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>모델 생성 결과는 'malignant melanoma'를 질병으로 사용했지만, 실제...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reason  score\n",
       "198  모델 생성 결과는 질문이 작성된 날짜와 답변이 채택된 날짜 사이의 일수를 구하는 쿼...  False\n",
       "199  모델 생성 결과는 'malignant melanoma'를 질병으로 사용했지만, 실제...  False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json_repair\n",
    "json_repair_df = pd.DataFrame([json_repair.loads(temp) for temp in prediction_eval_result])\n",
    "json_repair_df.tail(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 평균:  0.655\n"
     ]
    }
   ],
   "source": [
    "print(\"score 평균: \", sum(json_repair_df['score']) / len(json_repair_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
