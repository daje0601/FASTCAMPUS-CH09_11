{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# api key 관리를 위해 사용 \n",
    "load_dotenv(\"./env-credit\")\n",
    "huggingface_token = os.environ.get(\"HUGGINGFACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템(assistant)에게 주어진 역할\n",
    "system_message = \"당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.\"\n",
    "\n",
    "# 실제로 사용자 입력 -> 모델이 답해야 하는 프롬프트\n",
    "prompt = \"\"\"입력 정보:\n",
    "- name: {name}\n",
    "- image: [image]\n",
    "\n",
    "위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\n",
    "1) gender\n",
    "2) masterCategory\n",
    "3) subCategory\n",
    "4) season\n",
    "5) usage\n",
    "6) baseColour\n",
    "7) articleType\n",
    "\n",
    "출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\n",
    "{{\n",
    "  \"gender\": \"예시값\",\n",
    "  \"masterCategory\": \"예시값\",\n",
    "  \"subCategory\": \"예시값\",\n",
    "  \"season\": \"예시값\",\n",
    "  \"usage\": \"예시값\",\n",
    "  \"baseColour\": \"예시값\",\n",
    "  \"articleType\": \"예시값\"\n",
    "}}\n",
    "\n",
    "# 예시\n",
    "{{\n",
    "  \"gender\": \"Men\",\n",
    "  \"masterCategory\": \"Accessories\",\n",
    "  \"subCategory\": \"Eyewear\",\n",
    "  \"season\": \"Winter\",\n",
    "  \"usage\": \"Casual\",\n",
    "  \"baseColour\": \"Blue\",\n",
    "  \"articleType\": \"Sunglasses\"\n",
    "}}\n",
    "\n",
    "# 주의\n",
    "- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "def combine_cols_to_label(example):\n",
    "    # 실제 컬럼명에 맞게 수정\n",
    "    label_dict = {\n",
    "        \"gender\": example[\"gender\"],\n",
    "        \"masterCategory\": example[\"masterCategory\"],\n",
    "        \"subCategory\": example[\"subCategory\"],\n",
    "        \"season\": example[\"season\"],\n",
    "        \"usage\": example[\"usage\"],\n",
    "        \"baseColour\": example[\"baseColour\"],\n",
    "        \"articleType\": example[\"articleType\"],\n",
    "    }\n",
    "    example[\"label\"] = json.dumps(label_dict, ensure_ascii=False)\n",
    "    return example\n",
    "\n",
    "def format_data(sample):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": system_message\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt.format(name=sample[\"productDisplayName\"]),\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        # \"image_file\"라는 칼럼이 있다고 가정\n",
    "                        \"image\": sample[\"file_path\"],  \n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        # combine_cols_to_label에서 만든 JSON 문자열\n",
    "                        \"text\": sample[\"label\"],\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "dataset = load_dataset(\"daje/kaggle-image-datasets\", split=\"train\")\n",
    "dataset_add_label = dataset.map(combine_cols_to_label)\n",
    "dataset_add_label = dataset_add_label.shuffle(seed=4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=60x80>,\n",
       " 'id': 44429,\n",
       " 'gender': 'Men',\n",
       " 'masterCategory': 'Footwear',\n",
       " 'subCategory': 'Shoes',\n",
       " 'articleType': 'Formal Shoes',\n",
       " 'baseColour': 'Black',\n",
       " 'season': 'Summer',\n",
       " 'year': '2013',\n",
       " 'usage': 'Formal',\n",
       " 'productDisplayName': 'Gliders Men Black Formal Shoes',\n",
       " 'label': '{\"gender\": \"Men\", \"masterCategory\": \"Footwear\", \"subCategory\": \"Shoes\", \"season\": \"Summer\", \"usage\": \"Formal\", \"baseColour\": \"Black\", \"articleType\": \"Formal Shoes\"}'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_add_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_dataset = [format_data(row) for row in dataset_add_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.'}]},\n",
       "  {'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '입력 정보:\\n- name: Gliders Men Black Formal Shoes\\n- image: [image]\\n\\n위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\\n1) gender\\n2) masterCategory\\n3) subCategory\\n4) season\\n5) usage\\n6) baseColour\\n7) articleType\\n\\n출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\\n{\\n  \"gender\": \"예시값\",\\n  \"masterCategory\": \"예시값\",\\n  \"subCategory\": \"예시값\",\\n  \"season\": \"예시값\",\\n  \"usage\": \"예시값\",\\n  \"baseColour\": \"예시값\",\\n  \"articleType\": \"예시값\"\\n}\\n\\n# 예시\\n{\\n  \"gender\": \"Men\",\\n  \"masterCategory\": \"Accessories\",\\n  \"subCategory\": \"Eyewear\",\\n  \"season\": \"Winter\",\\n  \"usage\": \"Casual\",\\n  \"baseColour\": \"Blue\",\\n  \"articleType\": \"Sunglasses\"\\n}\\n\\n# 주의\\n- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\\n'},\n",
       "    {'type': 'image',\n",
       "     'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=60x80>}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '{\"gender\": \"Men\", \"masterCategory\": \"Footwear\", \"subCategory\": \"Shoes\", \"season\": \"Summer\", \"usage\": \"Formal\", \"baseColour\": \"Black\", \"articleType\": \"Formal Shoes\"}'}]}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test_size=0.1로 설정하여 전체 데이터의 10%를 테스트 세트로 분리\n",
    "train_dataset, test_dataset = train_test_split(formatted_dataset, \n",
    "                                             test_size=0.1, \n",
    "                                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39996, 4444)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c5fb5c38a348319bbd6fc965fa415b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "\n",
    "# 허깅페이스 모델 ID\n",
    "model_id = \"Qwen/Qwen2-VL-7B-Instruct\" \n",
    "\n",
    "# 모델과 프로세서 로드\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "   model_id,\n",
    "   device_map=\"auto\",                            # GPU 메모리에 자동 할당\n",
    "   torch_dtype=torch.bfloat16,                   # bfloat16 정밀도 사용\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)  # 텍스트/이미지 전처리기 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.<|im_end|>\n",
      "<|im_start|>user\n",
      "입력 정보:\n",
      "- name: Myntra Women's I Want You Black T-shirt\n",
      "- image: [image]\n",
      "\n",
      "위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\n",
      "1) gender\n",
      "2) masterCategory\n",
      "3) subCategory\n",
      "4) season\n",
      "5) usage\n",
      "6) baseColour\n",
      "7) articleType\n",
      "\n",
      "출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\n",
      "{\n",
      "  \"gender\": \"예시값\",\n",
      "  \"masterCategory\": \"예시값\",\n",
      "  \"subCategory\": \"예시값\",\n",
      "  \"season\": \"예시값\",\n",
      "  \"usage\": \"예시값\",\n",
      "  \"baseColour\": \"예시값\",\n",
      "  \"articleType\": \"예시값\"\n",
      "}\n",
      "\n",
      "# 예시\n",
      "{\n",
      "  \"gender\": \"Men\",\n",
      "  \"masterCategory\": \"Accessories\",\n",
      "  \"subCategory\": \"Eyewear\",\n",
      "  \"season\": \"Winter\",\n",
      "  \"usage\": \"Casual\",\n",
      "  \"baseColour\": \"Blue\",\n",
      "  \"articleType\": \"Sunglasses\"\n",
      "}\n",
      "\n",
      "# 주의\n",
      "- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\n",
      "<|vision_start|><|image_pad|><|vision_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"gender\": \"Women\", \"masterCategory\": \"Apparel\", \"subCategory\": \"Topwear\", \"season\": \"Summer\", \"usage\": \"Casual\", \"baseColour\": \"Black\", \"articleType\": \"Tshirts\"}<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    train_dataset[2][\"messages\"], tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig\n",
    "from transformers import Qwen2VLProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# 텍스트와 이미지 쌍을 인코딩하기 위한 데이터 collator 함수 정의\n",
    "def collate_fn(examples):\n",
    "    # 각 예제에서 텍스트와 이미지를 추출하고, 텍스트는 채팅 템플릿을 적용\n",
    "    texts = [processor.apply_chat_template(example[\"messages\"], tokenize=False) for example in examples]\n",
    "    image_inputs = [process_vision_info(example[\"messages\"])[0] for example in examples]\n",
    "\n",
    "    # 텍스트를 토크나이징하고 이미지를 처리하여 일괄 처리(batch) 형태로 변환\n",
    "    batch = processor(text=texts, images=image_inputs, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    # labels로 사용할 input_ids 복사본 생성 후, 패딩 토큰을 -100으로 설정하여 손실 계산 시 무시하도록 함\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    #######################\n",
    "    # 패딩 토큰 손실 계산 제외 #\n",
    "    #######################\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100  \n",
    "\n",
    "    # 특정 이미지 토큰 인덱스는 손실 계산에서 무시 (모델에 따라 다름)\n",
    "    if isinstance(processor, Qwen2VLProcessor):  \n",
    "        # Qwen2VL 모델의 이미지 토큰 인덱스\n",
    "        image_tokens = [151652, 151653, 151655]\n",
    "    else:\n",
    "        # 다른 모델에서 이미지 토큰 ID를 얻어 손실 계산에서 제외\n",
    "        image_tokens = [processor.tokenizer.convert_tokens_to_ids(processor.image_token)]\n",
    "    #########################################\n",
    "    # 손실 계산 시 이미지 토큰 인덱스를 무시하도록 설정 #\n",
    "    #########################################\n",
    "    for image_token_id in image_tokens:\n",
    "        labels[labels == image_token_id] = -100\n",
    "    \n",
    "    # 배치에 labels 추가 (손실 계산 시 사용)\n",
    "    batch[\"labels\"] = labels\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단일 예시 데이터:\n",
      "{'messages': [{'role': 'system', 'content': [{'type': 'text', 'text': '당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': '입력 정보:\\n- name: ADIDAS Men Navy Blue Tracksuit\\n- image: [image]\\n\\n위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\\n1) gender\\n2) masterCategory\\n3) subCategory\\n4) season\\n5) usage\\n6) baseColour\\n7) articleType\\n\\n출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\\n{\\n  \"gender\": \"예시값\",\\n  \"masterCategory\": \"예시값\",\\n  \"subCategory\": \"예시값\",\\n  \"season\": \"예시값\",\\n  \"usage\": \"예시값\",\\n  \"baseColour\": \"예시값\",\\n  \"articleType\": \"예시값\"\\n}\\n\\n# 예시\\n{\\n  \"gender\": \"Men\",\\n  \"masterCategory\": \"Accessories\",\\n  \"subCategory\": \"Eyewear\",\\n  \"season\": \"Winter\",\\n  \"usage\": \"Casual\",\\n  \"baseColour\": \"Blue\",\\n  \"articleType\": \"Sunglasses\"\\n}\\n\\n# 주의\\n- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\\n'}, {'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=60x80 at 0x7C335C220050>}]}, {'role': 'assistant', 'content': [{'type': 'text', 'text': '{\"gender\": \"Men\", \"masterCategory\": \"Apparel\", \"subCategory\": \"Bottomwear\", \"season\": \"Summer\", \"usage\": \"Sports\", \"baseColour\": \"Navy Blue\", \"articleType\": \"Tracksuits\"}'}]}]}\n"
     ]
    }
   ],
   "source": [
    "# 단일 예시 확인\n",
    "example = train_dataset[0]  # 데이터셋의 첫 번째 아이템\n",
    "print(\"단일 예시 데이터:\")\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "처리된 배치 데이터:\n",
      "입력 ID 형태: torch.Size([1, 363])\n",
      "어텐션 마스크 형태: torch.Size([1, 363])\n",
      "이미지 픽셀 형태: torch.Size([24, 1176])\n",
      "레이블 형태: torch.Size([1, 363])\n"
     ]
    }
   ],
   "source": [
    "# collate_fn 테스트 (배치 크기 1로)\n",
    "batch = collate_fn([example])\n",
    "print(\"\\n처리된 배치 데이터:\")\n",
    "print(\"입력 ID 형태:\", batch[\"input_ids\"].shape)\n",
    "print(\"어텐션 마스크 형태:\", batch[\"attention_mask\"].shape)\n",
    "print(\"이미지 픽셀 형태:\", batch[\"pixel_values\"].shape)\n",
    "print(\"레이블 형태:\", batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력에 대한 정수 인코딩 결과:\n",
      "tensor([151644,   8948,    198,  64795,  82528,  33704,  90667,  21329,  80573,\n",
      "        138017,  79632,   3153,      8,  42039, 126558,  45104,    101,  92031,\n",
      "            14, 141274,  32077,  60039,  18411,  57835, 126605,  42905, 128618,\n",
      "         97929,  54070, 142713,  78952,     13, 151645,    198, 151644,    872,\n",
      "           198,  43866,  28754,  60039,    510,     12,    829,     25,   9630,\n",
      "           915,   1911,  11012,  19036,   8697,  64740,   3083,    198,     12,\n",
      "          2168,     25,    508,   1805,   2533,  80901,  60039,  18411,  81718,\n",
      "        144059,  42039,     11, 136646,    220,     22,  19969,  21329,   1376,\n",
      "         19391, 128605,  93668,   4718, 141966,  17380,  57835, 126605,  33883,\n",
      "         55673,  50302,    510,     16,      8,   9825,    198,     17,      8,\n",
      "          7341,   6746,    198,     18,      8,   1186,   6746,    198,     19,\n",
      "             8,   3200,    198,     20,      8,  10431,    198,     21,      8,\n",
      "          2331,  33281,    198,     22,      8,   4549,    929,    271,  53496,\n",
      "         57133,  44518,   3070,  52959,  53442,   4718,  95617,  29326, 141966,\n",
      "           334,  18411, 141762,  66790, 126896,  50302,    510,    515,    220,\n",
      "           330,  12968,    788,    330, 127027,  29326,  82801,    756,    220,\n",
      "           330,  13629,   6746,    788,    330, 127027,  29326,  82801,    756,\n",
      "           220,    330,   1966,   6746,    788,    330, 127027,  29326,  82801,\n",
      "           756,    220,    330,  16798,    788,    330, 127027,  29326,  82801,\n",
      "           756,    220,    330,  17698,    788,    330, 127027,  29326,  82801,\n",
      "           756,    220,    330,   3152,  33281,    788,    330, 127027,  29326,\n",
      "         82801,    756,    220,    330,   7058,    929,    788,    330, 127027,\n",
      "         29326,  82801,    698,    630,      2,  95617,  29326,    198,    515,\n",
      "           220,    330,  12968,    788,    330,  28719,    756,    220,    330,\n",
      "         13629,   6746,    788,    330,   6054,   2433,    756,    220,    330,\n",
      "          1966,   6746,    788,    330,  97454,  98128,    756,    220,    330,\n",
      "         16798,    788,    330,  66188,    756,    220,    330,  17698,    788,\n",
      "           330,  49242,    928,    756,    220,    330,   3152,  33281,    788,\n",
      "           330,  10331,    756,    220,    330,   7058,    929,    788,    330,\n",
      "            50,   2185,  33868,    698,    630,      2,  55673,  20401,    198,\n",
      "            12,    220,     22,  59761, 142654,  87608,  23084, 128792,  20401,\n",
      "         60039,      7, 144153,  53189,     11,  53435,  40853,  77002,      8,\n",
      "         16560,  18585,    230,  66845, 133970,  87425,  95577,  50302,    624,\n",
      "        151652, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 151645,\n",
      "           198, 151644,  77091,    198,   4913,  12968,    788,    330,  28719,\n",
      "           497,    330,  13629,   6746,    788,    330,   2164,  30431,    497,\n",
      "           330,   1966,   6746,    788,    330,  11279,  22744,    497,    330,\n",
      "         16798,    788,    330,  50687,    497,    330,  17698,    788,    330,\n",
      "         40979,    497,    330,   3152,  33281,    788,    330,     45,   5663,\n",
      "          8697,    497,    330,   7058,    929,    788,    330,  52923,  11797,\n",
      "          9207, 151645,    198])\n"
     ]
    }
   ],
   "source": [
    "print('입력에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블에 대한 정수 인코딩 결과:\n",
      "tensor([151644,   8948,    198,  64795,  82528,  33704,  90667,  21329,  80573,\n",
      "        138017,  79632,   3153,      8,  42039, 126558,  45104,    101,  92031,\n",
      "            14, 141274,  32077,  60039,  18411,  57835, 126605,  42905, 128618,\n",
      "         97929,  54070, 142713,  78952,     13, 151645,    198, 151644,    872,\n",
      "           198,  43866,  28754,  60039,    510,     12,    829,     25,   9630,\n",
      "           915,   1911,  11012,  19036,   8697,  64740,   3083,    198,     12,\n",
      "          2168,     25,    508,   1805,   2533,  80901,  60039,  18411,  81718,\n",
      "        144059,  42039,     11, 136646,    220,     22,  19969,  21329,   1376,\n",
      "         19391, 128605,  93668,   4718, 141966,  17380,  57835, 126605,  33883,\n",
      "         55673,  50302,    510,     16,      8,   9825,    198,     17,      8,\n",
      "          7341,   6746,    198,     18,      8,   1186,   6746,    198,     19,\n",
      "             8,   3200,    198,     20,      8,  10431,    198,     21,      8,\n",
      "          2331,  33281,    198,     22,      8,   4549,    929,    271,  53496,\n",
      "         57133,  44518,   3070,  52959,  53442,   4718,  95617,  29326, 141966,\n",
      "           334,  18411, 141762,  66790, 126896,  50302,    510,    515,    220,\n",
      "           330,  12968,    788,    330, 127027,  29326,  82801,    756,    220,\n",
      "           330,  13629,   6746,    788,    330, 127027,  29326,  82801,    756,\n",
      "           220,    330,   1966,   6746,    788,    330, 127027,  29326,  82801,\n",
      "           756,    220,    330,  16798,    788,    330, 127027,  29326,  82801,\n",
      "           756,    220,    330,  17698,    788,    330, 127027,  29326,  82801,\n",
      "           756,    220,    330,   3152,  33281,    788,    330, 127027,  29326,\n",
      "         82801,    756,    220,    330,   7058,    929,    788,    330, 127027,\n",
      "         29326,  82801,    698,    630,      2,  95617,  29326,    198,    515,\n",
      "           220,    330,  12968,    788,    330,  28719,    756,    220,    330,\n",
      "         13629,   6746,    788,    330,   6054,   2433,    756,    220,    330,\n",
      "          1966,   6746,    788,    330,  97454,  98128,    756,    220,    330,\n",
      "         16798,    788,    330,  66188,    756,    220,    330,  17698,    788,\n",
      "           330,  49242,    928,    756,    220,    330,   3152,  33281,    788,\n",
      "           330,  10331,    756,    220,    330,   7058,    929,    788,    330,\n",
      "            50,   2185,  33868,    698,    630,      2,  55673,  20401,    198,\n",
      "            12,    220,     22,  59761, 142654,  87608,  23084, 128792,  20401,\n",
      "         60039,      7, 144153,  53189,     11,  53435,  40853,  77002,      8,\n",
      "         16560,  18585,    230,  66845, 133970,  87425,  95577,  50302,    624,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100, 151645,\n",
      "           198, 151644,  77091,    198,   4913,  12968,    788,    330,  28719,\n",
      "           497,    330,  13629,   6746,    788,    330,   2164,  30431,    497,\n",
      "           330,   1966,   6746,    788,    330,  11279,  22744,    497,    330,\n",
      "         16798,    788,    330,  50687,    497,    330,  17698,    788,    330,\n",
      "         40979,    497,    330,   3152,  33281,    788,    330,     45,   5663,\n",
      "          8697,    497,    330,   7058,    929,    788,    330,  52923,  11797,\n",
      "          9207, 151645,    198])\n"
     ]
    }
   ],
   "source": [
    "print('레이블에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"labels\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "디코딩된 텍스트:\n",
      "<|im_start|>system\n",
      "당신은 이미지와 제품명(name)으로부터 패션/스타일 정보를 추론하는 분류 모델입니다.<|im_end|>\n",
      "<|im_start|>user\n",
      "입력 정보:\n",
      "- name: ADIDAS Men Navy Blue Tracksuit\n",
      "- image: [image]\n",
      "\n",
      "위 정보를 바탕으로, 아래 7가지 key에 대한 값을 JSON 형태로 추론해 주세요:\n",
      "1) gender\n",
      "2) masterCategory\n",
      "3) subCategory\n",
      "4) season\n",
      "5) usage\n",
      "6) baseColour\n",
      "7) articleType\n",
      "\n",
      "출력 시 **아래 JSON 예시 형태**를 반드시 지키세요:\n",
      "{\n",
      "  \"gender\": \"예시값\",\n",
      "  \"masterCategory\": \"예시값\",\n",
      "  \"subCategory\": \"예시값\",\n",
      "  \"season\": \"예시값\",\n",
      "  \"usage\": \"예시값\",\n",
      "  \"baseColour\": \"예시값\",\n",
      "  \"articleType\": \"예시값\"\n",
      "}\n",
      "\n",
      "# 예시\n",
      "{\n",
      "  \"gender\": \"Men\",\n",
      "  \"masterCategory\": \"Accessories\",\n",
      "  \"subCategory\": \"Eyewear\",\n",
      "  \"season\": \"Winter\",\n",
      "  \"usage\": \"Casual\",\n",
      "  \"baseColour\": \"Blue\",\n",
      "  \"articleType\": \"Sunglasses\"\n",
      "}\n",
      "\n",
      "# 주의\n",
      "- 7개 항목 이외의 정보(텍스트, 문장 등)는 절대 포함하지 마세요.\n",
      "<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"gender\": \"Men\", \"masterCategory\": \"Apparel\", \"subCategory\": \"Bottomwear\", \"season\": \"Summer\", \"usage\": \"Sports\", \"baseColour\": \"Navy Blue\", \"articleType\": \"Tracksuits\"}<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 토큰 디코딩 예시 (입력 텍스트가 어떻게 변환되었는지 확인)\n",
    "decoded_text = processor.tokenizer.decode(batch[\"input_ids\"][0])\n",
    "print(\"\\n디코딩된 텍스트:\")\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=128,\n",
    "        lora_dropout=0.05,\n",
    "        r=256,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\n",
    "           \"q_proj\",    # Query 투영 레이어\n",
    "           \"up_proj\",   # FFN 상향 투영 레이어\n",
    "           \"o_proj\",    # Output 투영 레이어\n",
    "           \"k_proj\",    # Key 투영 레이어\n",
    "           \"down_proj\", # FFN 하향 투영 레이어\n",
    "           \"gate_proj\", # FFN 게이트 투영 레이어\n",
    "           \"v_proj\"     # Value 투영 레이어\n",
    "       ],\n",
    "        task_type=\"CAUSAL_LM\", \n",
    ")\n",
    "\n",
    "\n",
    "# SFTConfig를 통해 학습 설정을 정의\n",
    "args = SFTConfig(\n",
    "    output_dir=\"./kaggle_image_prediction_qkvupdg_1e-5_seperate\",   # 학습된 모델과 체크포인트를 저장할 디렉터리 경로 및 리포지토리 ID\n",
    "    # num_train_epochs=1,                                    # 전체 학습 에포크 수 (데이터셋을 몇 번 반복할지 설정)\n",
    "    max_steps=300,\n",
    "    per_device_train_batch_size=8,                         # 각 장비(GPU)당 사용될 배치 사이즈 (메모리와 연관됨)\n",
    "    gradient_accumulation_steps=8,                         # 경사 누적 스텝 수 (이 횟수만큼 기울기를 누적한 후 업데이트)\n",
    "    gradient_checkpointing=True,                           # 메모리 절약을 위한 gradient checkpointing 활성화 (메모리 최적화)\n",
    "    optim=\"adamw_torch_fused\",                             # AdamW 옵티마이저 (fused 버전 사용으로 학습 속도 향상)\n",
    "    logging_steps=50,                                      # 몇 스텝마다 로그를 출력할지 설정 (여기선 50 스텝마다 로그)\n",
    "    save_strategy=\"steps\",   \n",
    "    save_steps=50,                                        # 매 스텝마다 체크포인트 저장 설정\n",
    "    learning_rate=1e-5,                                    # 학습률 (LoRA 논문에서 추천된 값 사용)\n",
    "    bf16=True,                                             # bfloat16 정밀도 사용 (메모리 절약 및 속도 향상)\n",
    "    tf32=True,                                             # tf32 정밀도 사용 (NVIDIA GPU에서 학습 속도 향상)\n",
    "    max_grad_norm=0.3,                                     # 기울기 클리핑을 위한 최대 기울기 값 (LoRA 논문에서 추천된 값)\n",
    "    warmup_ratio=0.1,                                      # 학습 초기에 학습률을 점진적으로 올리는 warmup 비율 (LoRA 논문에서 추천된 값)\n",
    "    lr_scheduler_type=\"cosine\",                            # 일정한 학습률 스케줄러 사용 (학습률이 변하지 않음)\n",
    "    # push_to_hub=True,                                    # 학습된 모델을 Hugging Face Hub에 푸시할지 여부\n",
    "    report_to=\"none\",                                      # TensorBoard, wanbd 등 원하시는 사용하여 학습 상태를 모니터링\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},# reentrant gradient checkpointing 설정 (비재진입 방식 사용)\n",
    "    dataset_text_field=\"\",                                 # 데이터셋에서 텍스트 필드를 위한 더미 필드 (collator에서 필요)\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True}          # collator에서 데이터셋 전처리를 건너뛰기 위한 설정\n",
    ")\n",
    "\n",
    "# 불필요한 열 삭제하지 않도록 설정 (학습 중 사용되지 않는 열이라도 유지)\n",
    "args.remove_unused_columns = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 26:33, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.941200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.088900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.082500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.080300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=processor.tokenizer,\n",
    ")\n",
    "\n",
    "# 학습 시작, 모델은 자동으로 허브와 출력 디렉토리에 저장됨\n",
    "trainer.train()\n",
    "\n",
    "# 모델 저장\n",
    "trainer.save_model(args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 실험을 A6000에서 학습을 해보면, 1시간 30분 정도가 소요됩니다.\n",
    "- H100에서는 22분 정도 소요됩니다. 장비에 따라 연산속도가 어느 정도 차이가 나는지 한번 채감하실 수 있도록 테스트를 해보았습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
